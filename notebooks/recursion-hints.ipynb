{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "748686a2-6ca0-4c94-bd48-a8beb6e078fc",
   "metadata": {},
   "source": [
    "# Hints for harder `recursion.py` problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1758a0-07fe-4d53-a641-ef571eb4e42f",
   "metadata": {},
   "source": [
    "## `merge_sort_adaptive`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad9649e-d7bf-4a2d-a7e7-2f2b8f0862c7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>Hint 1</strong> <em>(click to reveal/hide)</em></summary>\n",
    "\n",
    "You run into Professor Run at the park where he runs backwards each morning. He tells you that runs of equal (or similar) values can be treated as rising runs or falling runs, so they won't break either kind of run if they appear within it. Is the professor right? Of increasing, decreasing, nonincreasing, and nondecreasing runs, which kinds should you detect?\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838a2c38-62be-455b-a9e0-637b2c65e48c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>Hint 2</strong> <em>(click to reveal/hide)</em></summary>\n",
    "\n",
    "You probably shouldn't overcomplicate your algorithm by treating only some parts of the input as runs. No matter what input you get, every element is part of a run, though sometimes the run is very short. Of course, you must find longer runs to get adaptive speedup.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9f773a-0ee2-4868-b672-43a5c1520bd4",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>Hint 3</strong> <em>(click to reveal/hide)</em></summary>\n",
    "\n",
    "Your algorithm may fail to sort some monotone inputs in $\\mathcal{O}(n)$ time, but those are fairly rare. To make up for it, your algorithm may succeed at sorting some inputs with frequent direction changes in $\\mathcal{O}(n)$ time. Whatever runs you take advantage of, detecting all such runs will take $\\mathcal{O}(n)$ time.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89a1fce-79f7-430e-a428-a6000b90bcea",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>Hint 4</strong> <em>(click to reveal/hide)</em></summary>\n",
    "\n",
    "Concatenating two lists sometimes behaves as a two-way merge. When? Such a merge is always stable. Why? Yet it's easy to accidentally design an unstable sort based on this insight. Why is that? Also, concatenation and two-way merge both take linear time. Yet this insight is still useful. How?\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4fa4a1-8208-4647-8b37-f13aafc0b25c",
   "metadata": {},
   "source": [
    "## `partition3_in_place` hints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8754f9-5dd6-40e4-abfb-bbf09cb659d8",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>Hint 1</strong> <em>(click to reveal/hide)</em></summary>\n",
    "\n",
    "Do all the mutations by swapping. If the time complexity is $\\mathcal{O}(f(n))$, you'll do $\\mathcal{O}(f(n))$ swaps.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3cc768-2011-44f2-a339-acd0b78dd908",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>Hint 2</strong> <em>(click to reveal/hide)</em></summary>\n",
    "\n",
    "It is tricky to do this elegantly. It is okay if your solution does a constant factor more swaps than an optimal solution (in the sense of doing the fewest possible swaps) would. Take advantage of how stability is not required.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d733e396-c051-4fd4-9025-e9dfa8255524",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>Hint 3</strong> <em>(click to reveal/hide)</em></summary>\n",
    "\n",
    "If you're having trouble efficiently partitioning the input in-place 3 ways, you can efficiently partition all of it in-place 2 ways and then partition part of it in-place 2 ways. For example, you could move the elements strictly less than the pivot before all those that are similar to or greater than it, and then move the elements strictly greater than the pivot after those that are similar to it. Make sure you understand why this works even though your in-place 2-way partitioning algorithm will itself be unstable.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e08879-5023-4c0b-9b5e-4bc03c387170",
   "metadata": {},
   "source": [
    "## `count_inversions` hints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79070e7-20ed-4d3e-bee4-ace5275751cc",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>Hint 1</strong> <em>(click to reveal/hide)</em></summary>\n",
    "\n",
    "Why is mergesort faster than insertion sort? Why is quicksort faster than selection sort? Why are these questions interesting?\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c8e409-5883-4319-a8c3-46f36624b0ef",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>Hint 2</strong> <em>(click to reveal/hide)</em></summary>\n",
    "\n",
    "\"Let me tell you about another time I was wrong,\" Professor Run says, as the two of you wait your turn for fish and absinthe. \"I used to always cut in line at these food trucks. I got so many dirty looks from everybody--well, from the people who started in *front* of me. I figured, I was making them wait just a little bit, and saving myself a long wait. But the little bits they all waited added up to the time I saved. I realized this when I started counting the dirty looks. It took so long just to count them, one by one!\"\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfe122c-9435-48b4-a3a8-6141f339bc58",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><strong>Hint 3</strong> <em>(click to reveal/hide)</em> &ndash; <strong>this gives away most of the solution</strong></summary>\n",
    "\n",
    "Suppose you want to know how long `merge_two_slow` takes. This is proportional to the number of times it moves an element to make room for an insertion. With most inputs, that happens many more times than the number of elements being merged. It is straightforward to instrument `merge_two_slow` to count how many times that happens. (Make sure you understand exactly how to do that.) But is there some way to instrument `merge_two` or `merge_two_alt` that would let you compute the same result in linear time?\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fce636-077b-4d5c-8011-68bbfa52bb5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
